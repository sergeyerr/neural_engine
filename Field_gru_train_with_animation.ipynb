{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GruCell(nn.Module):\n",
    "    def __init__(self, hidden_size = 10):\n",
    "        super(GruCell, self).__init__()\n",
    "        self.my_reset = nn.Linear(hidden_size, hidden_size)\n",
    "        self.my_update = nn.Linear(hidden_size, hidden_size)\n",
    "        self.my_final = nn.Linear(hidden_size, hidden_size)\n",
    "        self.neighbours_reset = nn.Linear(4 * hidden_size, hidden_size)\n",
    "        self.neighbours_update = nn.Linear(4 * hidden_size, hidden_size)\n",
    "        self.neighbours_final = nn.Linear(4 * hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, state, x):\n",
    "        reset_chooser = torch.sigmoid(self.my_reset(state) + self.neighbours_reset(x))\n",
    "        resetted = reset_chooser * state\n",
    "        update_chooser = torch.sigmoid(self.my_update(state) + self.neighbours_update(x))\n",
    "        update = torch.tanh(self.my_final(resetted) + self.neighbours_final(x))\n",
    "        update = update_chooser * update\n",
    "        new_state = (1 - update_chooser) * state + update\n",
    "        return reset_chooser, update_chooser, update, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autism_loss(reset, update, delta, state):\n",
    "    return -torch.mean(reset ** 2) - torch.mean(update ** 2)  - torch.mean(state ** 2)  + torch.mean(delta ** 2)\n",
    "\n",
    "def anti_autism_loss(reset, update, delta, state):\n",
    "    return -torch.mean(reset ** 2) - torch.mean(update ** 2)  + torch.mean(state ** 2)  + torch.mean(delta ** 2)\n",
    "\n",
    "def distance_loss(states, x, y):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    middle = int(x.shape[0] / 2)\n",
    "    x1 = x[:middle]\n",
    "    x2 = x[middle:]\n",
    "    y1 = y[:middle]\n",
    "    y2 = y[middle:]\n",
    "    states1 = states[:middle]\n",
    "    states2 = states[middle:]\n",
    "    range_deltas = ((x2-x1) ** 2 + (y2-y1) ** 2 - torch.sum((states2 - states1) ** 2, axis = 1)) / 1000\n",
    "    return torch.mean(range_deltas ** 2) ** 0.5 \n",
    "    \n",
    "\n",
    "def prefer_biggest_loss(reset, update, delta, state):\n",
    "    priority = torch.mean(state ** 2, axis = 1)\n",
    "    priority = priority.reshape(delta.shape[0], 1)\n",
    "    return - torch.mean(priority * reset ** 2) - torch.mean(priority * update ** 2)  + torch.mean(priority * delta ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_size = 102\n",
    "hidden_size = 8\n",
    "epochs = 15\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_pos = GruCell(hidden_size).to(device)\n",
    "net_neg = GruCell(hidden_size).to(device)\n",
    "optimizer_pos = optim.Adam(net_pos.parameters(), lr=0.0001, weight_decay = 0.001)\n",
    "optimizer_neg = optim.Adam(net_neg.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = torch.randn(field_size, field_size, hidden_size)\n",
    "# зануляем края\n",
    "for i in range(field_size):\n",
    "    for j in range(field_size):\n",
    "        if i == 0 or j == 0 or i == field_size - 1 or j == field_size - 1:\n",
    "            field[i, j] = torch.zeros(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pump_energy = False\n",
    "for e in range(epochs):\n",
    "    new_field = torch.zeros(field_size, field_size, hidden_size)\n",
    "    train_set = []\n",
    "    for i in range(1, field_size - 1):\n",
    "        for j in range(1, field_size - 1):\n",
    "            tmp = []\n",
    "            tmp.append(field[i, j].to(device))\n",
    "            # верхние и боковые соседи\n",
    "            tmp.append(torch.cat([field[i - 1, j], field[i + 1, j], field[i, j - 1], field[i, j + 1]]).to(device))\n",
    "            # координаты поля\n",
    "            tmp.append((i, j))\n",
    "            train_set.append(tmp)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    running_loss = 0.0\n",
    "    for cells, neighbours, cords in train_loader:\n",
    "        loc_y, loc_x = cords\n",
    "        optimizer_pos.zero_grad()\n",
    "        optimizer_neg.zero_grad()\n",
    "        reset_pos, update_pos, delta_pos, state_pos = net_pos(cells, neighbours)\n",
    "        reset_neg, update_neg , delta_neg, state_neg = net_neg(cells, neighbours)\n",
    "        mask = delta_pos > delta_neg\n",
    "        loss_neg = anti_autism_loss(mask * reset_neg, mask *  update_neg, mask *  delta_neg, mask *  state_neg) \n",
    "        loss_pos = autism_loss(~mask * reset_pos, ~mask * update_pos, ~mask * delta_pos, ~mask * state_pos) * 0.5\n",
    "        loss_pos.backward()\n",
    "        loss_neg.backward()\n",
    "        optimizer_pos.step()\n",
    "        optimizer_neg.step()\n",
    "        with torch.no_grad():\n",
    "            for new_state, y, x, m in zip(state_pos, loc_y, loc_x, mask.cpu().numpy()):\n",
    "                if m[0]:\n",
    "                    new_field[y, x] = new_state\n",
    "            for new_state, y, x, m in zip(state_neg, loc_y, loc_x, mask.cpu().numpy()):\n",
    "                if not m[0]:\n",
    "                    new_field[y, x] = new_state.to('cpu')\n",
    "        # print statistics\n",
    "        running_loss += loss_pos.item()\n",
    "    mean_information = torch.mean(field ** 2)\n",
    "    with torch.no_grad():\n",
    "        field = new_field.clone()\n",
    "        fig, ax = plt.subplots(figsize=(10,10))   \n",
    "        ax = sns.heatmap(torch.mean(field ** 2, axis = 2), ax=ax, square=True,  vmin = 0, vmax = 1)\n",
    "        plt.show()\n",
    "        if pump_energy:\n",
    "            # эксмерементирую с константой, сколько нового рандома вносить\n",
    "            field += torch.randn(field_size, field_size, hidden_size) * 0.3\n",
    "    print(f'[{e + 1}] loss: {running_loss /  len(train_loader):.3f}; Mean Information : {torch.mean(field ** 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'models/first_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
